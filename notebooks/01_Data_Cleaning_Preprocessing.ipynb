{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e335da-494d-4565-826f-a214b040d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bb00af-f580-41ab-9828-da0703eb9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (33904, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202503</td>\n",
       "      <td>31</td>\n",
       "      <td>1104</td>\n",
       "      <td>202503</td>\n",
       "      <td>31</td>\n",
       "      <td>1106</td>\n",
       "      <td>201366</td>\n",
       "      <td>1252415</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>W</td>\n",
       "      <td>TYUS</td>\n",
       "      <td>33.4757</td>\n",
       "      <td>-85.238</td>\n",
       "      <td>33.4757</td>\n",
       "      <td>-85.238</td>\n",
       "      <td>A cold-front initiated a line of thunderstorms...</td>\n",
       "      <td>Tree down at the intersection of highway 5 and...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202503</td>\n",
       "      <td>30</td>\n",
       "      <td>1552</td>\n",
       "      <td>202503</td>\n",
       "      <td>30</td>\n",
       "      <td>1555</td>\n",
       "      <td>200337</td>\n",
       "      <td>1241136</td>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>EDWARDSBURG</td>\n",
       "      <td>41.7900</td>\n",
       "      <td>-86.100</td>\n",
       "      <td>41.8200</td>\n",
       "      <td>-86.070</td>\n",
       "      <td>A cold front pushed into the area during the a...</td>\n",
       "      <td>A brief EF-1 tornado was confirmed in Edwardsb...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202501</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>202501</td>\n",
       "      <td>6</td>\n",
       "      <td>2227</td>\n",
       "      <td>197733</td>\n",
       "      <td>1222851</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An area of low pressure tracked across souther...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202501</td>\n",
       "      <td>3</td>\n",
       "      <td>1300</td>\n",
       "      <td>202501</td>\n",
       "      <td>3</td>\n",
       "      <td>1900</td>\n",
       "      <td>197761</td>\n",
       "      <td>1223112</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An area of low pressure moved off into New Eng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202501</td>\n",
       "      <td>3</td>\n",
       "      <td>1300</td>\n",
       "      <td>202501</td>\n",
       "      <td>3</td>\n",
       "      <td>1900</td>\n",
       "      <td>197761</td>\n",
       "      <td>1223113</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An area of low pressure moved off into New Eng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           202503         31        1104         202503       31      1106   \n",
       "1           202503         30        1552         202503       30      1555   \n",
       "2           202501          5        1800         202501        6      2227   \n",
       "3           202501          3        1300         202501        3      1900   \n",
       "4           202501          3        1300         202501        3      1900   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID     STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0      201366   1252415   GEORGIA          13  ...        2.0           W   \n",
       "1      200337   1241136  MICHIGAN          26  ...        1.0         NNE   \n",
       "2      197733   1222851  VIRGINIA          51  ...        NaN         NaN   \n",
       "3      197761   1223112  MARYLAND          24  ...        NaN         NaN   \n",
       "4      197761   1223113  MARYLAND          24  ...        NaN         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT  BEGIN_LON  END_LAT END_LON  \\\n",
       "0         TYUS   33.4757    -85.238  33.4757 -85.238   \n",
       "1  EDWARDSBURG   41.7900    -86.100  41.8200 -86.070   \n",
       "2          NaN       NaN        NaN      NaN     NaN   \n",
       "3          NaN       NaN        NaN      NaN     NaN   \n",
       "4          NaN       NaN        NaN      NaN     NaN   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  A cold-front initiated a line of thunderstorms...   \n",
       "1  A cold front pushed into the area during the a...   \n",
       "2  An area of low pressure tracked across souther...   \n",
       "3  An area of low pressure moved off into New Eng...   \n",
       "4  An area of low pressure moved off into New Eng...   \n",
       "\n",
       "                                     EVENT_NARRATIVE DATA_SOURCE  \n",
       "0  Tree down at the intersection of highway 5 and...         CSV  \n",
       "1  A brief EF-1 tornado was confirmed in Edwardsb...         CSV  \n",
       "2                                                NaN         CSV  \n",
       "3                                                NaN         CSV  \n",
       "4                                                NaN         CSV  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw dataset (with messy K, M, B values)\n",
    "df = pd.read_csv(\"../data/raw/StormEvents_rawDATA.csv\")\n",
    "\n",
    "print(\"Initial Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5f155d-a3c5-42fe-9d00-9221bb44711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping irrelevant columns: (33904, 43)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"EPISODE_ID\", \"EVENT_ID\", \n",
    "    \"EPISODE_NARRATIVE\", \"EVENT_NARRATIVE\", \n",
    "    \"BEGIN_DATE_TIME\", \"END_DATE_TIME\", \n",
    "    \"STATE_FIPS\", \"CZ_FIPS\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "print(\"Shape after dropping irrelevant columns:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9aa3a09-6bfb-49ca-9b77-675ab536d3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY              33904\n",
       "TOR_OTHER_CZ_FIPS     33689\n",
       "TOR_OTHER_CZ_STATE    33689\n",
       "TOR_OTHER_WFO         33689\n",
       "TOR_OTHER_CZ_NAME     33689\n",
       "TOR_F_SCALE           32912\n",
       "TOR_LENGTH            32912\n",
       "TOR_WIDTH             32912\n",
       "FLOOD_CAUSE           30918\n",
       "MAGNITUDE_TYPE        20733\n",
       "MAGNITUDE             15520\n",
       "BEGIN_LON             14806\n",
       "END_LAT               14806\n",
       "END_LOCATION          14806\n",
       "BEGIN_LAT             14806\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "df.isna().sum().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bba5f9-c635-4b83-af11-11f3cd85b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros in DAMAGE_PROPERTY: 34\n",
      "Zeros in DAMAGE_CROPS: 0\n",
      "NaNs in DAMAGE_PROPERTY: 0\n",
      "NaNs in DAMAGE_CROPS: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.390400e+04</td>\n",
       "      <td>33904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.544749e+05</td>\n",
       "      <td>84818.338013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.099775e+05</td>\n",
       "      <td>103351.103213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.199208e+04</td>\n",
       "      <td>3998.458744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.207273e+04</td>\n",
       "      <td>4013.935459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000646e+05</td>\n",
       "      <td>200012.564817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.715994e+06</td>\n",
       "      <td>572001.791319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DAMAGE_PROPERTY   DAMAGE_CROPS\n",
       "count     3.390400e+04   33904.000000\n",
       "mean      2.544749e+05   84818.338013\n",
       "std       3.099775e+05  103351.103213\n",
       "min       0.000000e+00       0.000004\n",
       "25%       1.199208e+04    3998.458744\n",
       "50%       1.207273e+04    4013.935459\n",
       "75%       6.000646e+05  200012.564817\n",
       "max       1.715994e+06  572001.791319"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_damage(value):\n",
    "    if pd.isna(value):\n",
    "        return 0.0\n",
    "    \n",
    "    s = str(value).strip().upper()\n",
    "    \n",
    "    # Remove accidental spaces inside (e.g. \"10 K\")\n",
    "    s = s.replace(\" \", \"\")\n",
    "    \n",
    "    try:\n",
    "        if s.endswith(\"K\"):\n",
    "            return float(s[:-1]) * 1_000\n",
    "        elif s.endswith(\"M\"):\n",
    "            return float(s[:-1]) * 1_000_000\n",
    "        elif s.endswith(\"B\"):\n",
    "            return float(s[:-1]) * 1_000_000_000\n",
    "        else:\n",
    "            return float(s)  # plain number without suffix\n",
    "    except ValueError:\n",
    "        # Instead of silently returning 0, mark as NaN so we can count them\n",
    "        return np.nan\n",
    "df[\"DAMAGE_PROPERTY\"] = df[\"DAMAGE_PROPERTY\"].apply(convert_damage)\n",
    "df[\"DAMAGE_CROPS\"] = df[\"DAMAGE_CROPS\"].apply(convert_damage)\n",
    "\n",
    "# Report how many NaNs or 0s we created\n",
    "print(\"Zeros in DAMAGE_PROPERTY:\", (df[\"DAMAGE_PROPERTY\"] == 0).sum())\n",
    "print(\"Zeros in DAMAGE_CROPS:\", (df[\"DAMAGE_CROPS\"] == 0).sum())\n",
    "print(\"NaNs in DAMAGE_PROPERTY:\", df[\"DAMAGE_PROPERTY\"].isna().sum())\n",
    "print(\"NaNs in DAMAGE_CROPS:\", df[\"DAMAGE_CROPS\"].isna().sum())\n",
    "\n",
    "df[[\"DAMAGE_PROPERTY\", \"DAMAGE_CROPS\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3b42e1-11a5-4287-a567-f7ab807be749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Column 'CATEGORY' is entirely NaN -> dropping it.\n",
      "✅ Missing values handled safely.\n"
     ]
    }
   ],
   "source": [
    "# Fill numeric NaNs with median, but check for all-NaN columns\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isna().all():\n",
    "        print(f\"⚠️ Column '{col}' is entirely NaN -> dropping it.\")\n",
    "        df = df.drop(columns=[col])\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill categorical NaNs with mode\n",
    "for col in df.select_dtypes(include=[object]).columns:\n",
    "    if df[col].isna().all():\n",
    "        print(f\"⚠️ Column '{col}' is entirely NaN -> dropping it.\")\n",
    "        df = df.drop(columns=[col])\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"✅ Missing values handled safely.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8df7c6-c1cb-4c63-a18c-31b788772aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns encoded.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical columns encoded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "055fd719-dc81-4814-a4eb-8006d2ba302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved at ../data/interim/StormEvents_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"../data/interim/StormEvents_cleaned.csv\", index=False)\n",
    "print(\"✅ Cleaned dataset saved at ../data/interim/StormEvents_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d4ce8f-a23f-47cb-868e-98750998228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features scaled.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Exclude target columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop(\n",
    "    [\"DAMAGE_PROPERTY\", \"DAMAGE_CROPS\"], errors=\"ignore\"\n",
    ")\n",
    "\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"Numeric features scaled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8324cd-5389-4337-8ca6-885dd6c07f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed dataset saved at ../data/processed/StormEvents_features.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"../data/processed/StormEvents_features.csv\", index=False)\n",
    "print(\"✅ Processed dataset saved at ../data/processed/StormEvents_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6a9a265-8ab4-4733-80fd-4c9a1a8da721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAMAGE_PROPERTY summary:\n",
      " count    3.390400e+04\n",
      "mean     2.544749e+05\n",
      "std      3.099775e+05\n",
      "min      0.000000e+00\n",
      "25%      1.199208e+04\n",
      "50%      1.207273e+04\n",
      "75%      6.000646e+05\n",
      "max      1.715994e+06\n",
      "Name: DAMAGE_PROPERTY, dtype: float64\n",
      "\n",
      "DAMAGE_CROPS summary:\n",
      " count     33904.000000\n",
      "mean      84818.338013\n",
      "std      103351.103213\n",
      "min           0.000004\n",
      "25%        3998.458744\n",
      "50%        4013.935459\n",
      "75%      200012.564817\n",
      "max      572001.791319\n",
      "Name: DAMAGE_CROPS, dtype: float64\n",
      "\n",
      "Unique values in property (sample): DAMAGE_PROPERTY\n",
      "0.000000         34\n",
      "12012.098114      1\n",
      "11904.335988      1\n",
      "11913.754108      1\n",
      "11984.087754      1\n",
      "599969.914669     1\n",
      "12007.592383      1\n",
      "11961.357329      1\n",
      "8971.885624       1\n",
      "12063.616035      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in crops (sample): DAMAGE_CROPS\n",
      "207982.396695    1\n",
      "3982.285606      1\n",
      "4004.350395      1\n",
      "3987.631238      1\n",
      "3994.990350      1\n",
      "4000.631729      1\n",
      "4006.753008      1\n",
      "3997.789179      1\n",
      "4017.791718      1\n",
      "3999.995610      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of zeros in property: 34\n",
      "Number of zeros in crops: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"DAMAGE_PROPERTY summary:\\n\", df[\"DAMAGE_PROPERTY\"].describe())\n",
    "print(\"\\nDAMAGE_CROPS summary:\\n\", df[\"DAMAGE_CROPS\"].describe())\n",
    "\n",
    "print(\"\\nUnique values in property (sample):\", df[\"DAMAGE_PROPERTY\"].value_counts().head(10))\n",
    "print(\"\\nUnique values in crops (sample):\", df[\"DAMAGE_CROPS\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nNumber of zeros in property:\", (df[\"DAMAGE_PROPERTY\"] == 0).sum())\n",
    "print(\"Number of zeros in crops:\", (df[\"DAMAGE_CROPS\"] == 0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b5860-3b91-42d3-baef-bc7dae7bfea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv FDM)",
   "language": "python",
   "name": "fdm-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
